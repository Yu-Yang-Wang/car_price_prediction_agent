"""Embeddingç®¡ç†å™¨ï¼Œç”¨äºç”Ÿæˆå’Œç®¡ç†æ–‡æœ¬åµŒå…¥

å¢å¼ºç‚¹ï¼š
- æ”¯æŒé€šè¿‡ç¯å¢ƒå˜é‡é…ç½®æä¾›æ–¹ä¸æ¨¡å‹ï¼š
  - `EMBEDDINGS_PROVIDER` = "openai" | "huggingface"ï¼ˆç¼ºçœè‡ªåŠ¨é€‰æ‹©ï¼‰
  - `OPENAI_EMBEDDING_MODEL`ï¼ˆç¼ºçœ: text-embedding-ada-002ï¼‰
  - `HF_EMBEDDING_MODEL`ï¼ˆç¼ºçœ: sentence-transformers/all-MiniLM-L6-v2ï¼‰
- å…¬å¼€ `provider`ã€`model_id`ã€`embedding_dim` ä¾›å‘é‡åº“åšç‰ˆæœ¬åŒ–é›†åˆå‘½å
"""

import os
from typing import List, Dict, Any, Optional
import numpy as np
from langchain_openai import OpenAIEmbeddings
from langchain_huggingface import HuggingFaceEmbeddings
import logging

logger = logging.getLogger(__name__)


class EmbeddingManager:
    """åµŒå…¥ç®¡ç†å™¨"""

    def __init__(self,
                 model_name: Optional[str] = None,
                 openai_model: Optional[str] = None,
                 huggingface_model: Optional[str] = None):
        """åˆå§‹åŒ–åµŒå…¥ç®¡ç†å™¨

        Args:
            model_name: æ¨¡å‹åç§° ("openai" æˆ– "huggingface")
            openai_model: OpenAIåµŒå…¥æ¨¡å‹åç§°
            huggingface_model: HuggingFaceåµŒå…¥æ¨¡å‹åç§°
        """
        # è§£æé…ç½®ä¼˜å…ˆçº§ï¼š
        # 1) æ˜¾å¼ä¼ å‚ model_name
        # 2) ç¯å¢ƒå˜é‡ EMBEDDINGS_PROVIDER
        # 3) è‡ªåŠ¨ï¼šå¦‚æœæœ‰ OPENAI_API_KEY ç”¨ openaiï¼Œå¦åˆ™ huggingface

        env_provider = os.getenv("EMBEDDINGS_PROVIDER")
        provider = (model_name or env_provider or "auto").lower()

        # è¯»å–æ¨¡å‹åï¼Œæ”¯æŒç¯å¢ƒå˜é‡è¦†ç›–
        openai_model = openai_model or os.getenv("OPENAI_EMBEDDING_MODEL") or "text-embedding-ada-002"
        huggingface_model = huggingface_model or os.getenv("HF_EMBEDDING_MODEL") or "sentence-transformers/all-MiniLM-L6-v2"

        if provider == "auto":
            if os.getenv("OPENAI_API_KEY"):
                provider = "openai"
            else:
                provider = "huggingface"

        self.provider = provider  # openai | huggingface
        self.model_id = None      # å…·ä½“çš„æ¨¡å‹æ ‡è¯†å­—ç¬¦ä¸²

        if provider == "openai":
            if not os.getenv("OPENAI_API_KEY"):
                logger.warning("EMBEDDINGS_PROVIDER=openai ä½†æœªå‘ç° OPENAI_API_KEYï¼Œå›é€€è‡³ HuggingFace")
                self._init_huggingface(huggingface_model)
            else:
                self._init_openai(openai_model)
        else:
            self._init_huggingface(huggingface_model)

    def _init_openai(self, model: str):
        """åˆå§‹åŒ–OpenAIåµŒå…¥"""
        try:
            self.embeddings = OpenAIEmbeddings(
                model=model,
                chunk_size=1000
            )
            self.embedding_dim = 1536  # text-embedding-ada-002 dimension
            self.provider = "openai"
            self.model_id = model
            print(f"ğŸ¤– Initialized OpenAI embeddings: {model}")
        except Exception as e:
            logger.error(f"Failed to initialize OpenAI embeddings: {e}")
            # é™çº§åˆ°HuggingFace
            self._init_huggingface("sentence-transformers/all-MiniLM-L6-v2")

    def _init_huggingface(self, model: str):
        """åˆå§‹åŒ–HuggingFaceåµŒå…¥"""
        try:
            self.embeddings = HuggingFaceEmbeddings(
                model_name=model,
                model_kwargs={'device': 'cpu'},
                encode_kwargs={'normalize_embeddings': True}
            )
            self.embedding_dim = 384  # all-MiniLM-L6-v2 dimension
            self.provider = "huggingface"
            self.model_id = model
            print(f"ğŸ¤— Initialized HuggingFace embeddings: {model}")
        except Exception as e:
            logger.error(f"Failed to initialize HuggingFace embeddings: {e}")
            raise

    def embed_text(self, text: str) -> List[float]:
        """ä¸ºå•ä¸ªæ–‡æœ¬ç”ŸæˆåµŒå…¥

        Args:
            text: è¾“å…¥æ–‡æœ¬

        Returns:
            åµŒå…¥å‘é‡
        """
        try:
            if not text or not text.strip():
                return [0.0] * self.embedding_dim

            embedding = self.embeddings.embed_query(text)
            return embedding

        except Exception as e:
            logger.error(f"Error embedding text: {e}")
            return [0.0] * self.embedding_dim

    def embed_texts(self, texts: List[str]) -> List[List[float]]:
        """ä¸ºå¤šä¸ªæ–‡æœ¬ç”ŸæˆåµŒå…¥

        Args:
            texts: æ–‡æœ¬åˆ—è¡¨

        Returns:
            åµŒå…¥å‘é‡åˆ—è¡¨
        """
        try:
            # è¿‡æ»¤ç©ºæ–‡æœ¬
            valid_texts = [text if text and text.strip() else " " for text in texts]
            embeddings = self.embeddings.embed_documents(valid_texts)
            return embeddings

        except Exception as e:
            logger.error(f"Error embedding texts: {e}")
            return [[0.0] * self.embedding_dim] * len(texts)

    def calculate_similarity(self,
                           embedding1: List[float],
                           embedding2: List[float]) -> float:
        """è®¡ç®—ä¸¤ä¸ªåµŒå…¥å‘é‡çš„ä½™å¼¦ç›¸ä¼¼åº¦

        Args:
            embedding1: ç¬¬ä¸€ä¸ªåµŒå…¥å‘é‡
            embedding2: ç¬¬äºŒä¸ªåµŒå…¥å‘é‡

        Returns:
            ä½™å¼¦ç›¸ä¼¼åº¦ (-1 åˆ° 1)
        """
        try:
            vec1 = np.array(embedding1)
            vec2 = np.array(embedding2)

            # è®¡ç®—ä½™å¼¦ç›¸ä¼¼åº¦
            dot_product = np.dot(vec1, vec2)
            norm1 = np.linalg.norm(vec1)
            norm2 = np.linalg.norm(vec2)

            if norm1 == 0 or norm2 == 0:
                return 0.0

            similarity = dot_product / (norm1 * norm2)
            return float(similarity)

        except Exception as e:
            logger.error(f"Error calculating similarity: {e}")
            return 0.0

    def create_car_description(self, car_data: Dict[str, Any]) -> str:
        """ä¸ºæ±½è½¦æ•°æ®åˆ›å»ºæè¿°æ€§æ–‡æœ¬ï¼Œç”¨äºåµŒå…¥

        Args:
            car_data: æ±½è½¦æ•°æ®å­—å…¸

        Returns:
            æè¿°æ€§æ–‡æœ¬
        """
        try:
            year = car_data.get('year', '')
            make = car_data.get('make', '')
            model = car_data.get('model', '')
            mileage = car_data.get('mileage', 0)
            price = car_data.get('price_paid', 0)
            trim = car_data.get('trim', '')
            color = car_data.get('color', '')
            transmission = car_data.get('transmission', '')
            engine = car_data.get('engine', '')
            fuel_type = car_data.get('fuel_type', '')
            condition = car_data.get('condition', '')
            location = car_data.get('location', '')

            # æ„å»ºæè¿°æ€§æ–‡æœ¬
            parts = []

            # åŸºæœ¬ä¿¡æ¯
            if year and make and model:
                basic = f"{year} {make} {model}"
                if trim:
                    basic += f" {trim}"
                parts.append(basic)

            # é‡Œç¨‹å’Œä»·æ ¼
            if mileage:
                parts.append(f"{mileage:,} miles")
            if price:
                parts.append(f"${price:,.0f}")

            # è¯¦ç»†ä¿¡æ¯
            details = []
            if color:
                details.append(f"{color} color")
            if transmission:
                details.append(f"{transmission} transmission")
            if engine:
                details.append(f"{engine} engine")
            if fuel_type:
                details.append(f"{fuel_type} fuel")
            if condition:
                details.append(f"{condition} condition")
            if location:
                details.append(f"located in {location}")

            if details:
                parts.append(", ".join(details))

            description = ". ".join(parts)

            # æ·»åŠ åŸå§‹æ–‡æœ¬ï¼ˆå¦‚æœæœ‰ï¼‰
            raw_text = car_data.get('raw_text', '')
            if raw_text and len(raw_text.strip()) > 0:
                description += f". Additional details: {raw_text[:200]}"

            return description

        except Exception as e:
            logger.error(f"Error creating car description: {e}")
            return f"{car_data.get('year', '')} {car_data.get('make', '')} {car_data.get('model', '')}"

    def create_analysis_description(self, analysis_data: Dict[str, Any]) -> str:
        """ä¸ºåˆ†æç»“æœåˆ›å»ºæè¿°æ€§æ–‡æœ¬

        Args:
            analysis_data: åˆ†ææ•°æ®å­—å…¸

        Returns:
            æè¿°æ€§æ–‡æœ¬
        """
        try:
            parts = []

            # è¯„åˆ†ä¿¡æ¯
            rule_score = analysis_data.get('rule_based_score')
            rule_verdict = analysis_data.get('rule_based_verdict')
            llm_score = analysis_data.get('llm_score')
            llm_verdict = analysis_data.get('llm_verdict')

            if rule_score is not None and rule_verdict:
                parts.append(f"Rule-based analysis: {rule_score}/100 ({rule_verdict})")

            if llm_score is not None and llm_verdict:
                parts.append(f"LLM analysis: {llm_score}/100 ({llm_verdict})")

            # ä»·æ ¼åˆ†æ
            market_price = analysis_data.get('market_median_price')
            price_delta = analysis_data.get('price_delta')
            price_delta_percent = analysis_data.get('price_delta_percent')

            if market_price is not None:
                parts.append(f"Market median price: ${market_price:,.0f}")

            if price_delta is not None and price_delta_percent is not None:
                direction = "above" if price_delta > 0 else "below"
                parts.append(f"Price is ${abs(price_delta):,.0f} ({abs(price_delta_percent):.1f}%) {direction} market")

            # æ•°æ®è´¨é‡
            comparable_count = analysis_data.get('comparable_count')
            data_source = analysis_data.get('data_source')

            if comparable_count:
                parts.append(f"Based on {comparable_count} comparable vehicles")

            if data_source:
                parts.append(f"Data source: {data_source}")

            # LLMæ¨ç†
            llm_reasoning = analysis_data.get('llm_reasoning', '')
            if llm_reasoning:
                parts.append(f"Analysis reasoning: {llm_reasoning[:300]}")

            return ". ".join(parts)

        except Exception as e:
            logger.error(f"Error creating analysis description: {e}")
            return "Analysis data available"

    def create_knowledge_text(self, knowledge_data: Dict[str, Any]) -> str:
        """ä¸ºçŸ¥è¯†åº“æ¡ç›®åˆ›å»ºå®Œæ•´æ–‡æœ¬

        Args:
            knowledge_data: çŸ¥è¯†æ•°æ®å­—å…¸

        Returns:
            å®Œæ•´æ–‡æœ¬
        """
        try:
            title = knowledge_data.get('title', '')
            content = knowledge_data.get('content', '')
            category = knowledge_data.get('category', '')
            tags = knowledge_data.get('tags', [])

            parts = []

            if title:
                parts.append(f"Title: {title}")

            if category:
                parts.append(f"Category: {category}")

            if tags:
                parts.append(f"Tags: {', '.join(tags)}")

            if content:
                parts.append(f"Content: {content}")

            return ". ".join(parts)

        except Exception as e:
            logger.error(f"Error creating knowledge text: {e}")
            return knowledge_data.get('content', '')

    def get_embedding_info(self) -> Dict[str, Any]:
        """è·å–åµŒå…¥æ¨¡å‹ä¿¡æ¯

        Returns:
            æ¨¡å‹ä¿¡æ¯å­—å…¸
        """
        return {
            'model_name': self.model_name,
            'embedding_dimension': self.embedding_dim,
            'model_type': type(self.embeddings).__name__
        }
